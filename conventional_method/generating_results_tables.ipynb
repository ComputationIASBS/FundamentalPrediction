{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drowning Iran Inflation Chart\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "\n",
    "# Data from the CSV file\n",
    "data = pd.read_csv(\"Iran_Inflation.csv\")\n",
    "\n",
    "# Extracting year and inflation values\n",
    "years = data[\"Year\"]\n",
    "inflation = data[\"Inflation\"]\n",
    "\n",
    "# Calculate average inflation\n",
    "average_inflation = inflation.mean()\n",
    "\n",
    "# Custom settings for the plot\n",
    "mpl.rcParams.update({\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times New Roman'],\n",
    "    'font.size': 12,\n",
    "    'font.weight': 'normal',\n",
    "    'axes.labelsize': 12,\n",
    "    'axes.titlesize': 14,\n",
    "    'axes.titleweight': 'bold',\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'legend.fontsize': 12,\n",
    "})\n",
    "\n",
    "# Create a line chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(years, inflation, marker='o', color='skyblue', label='Inflation')\n",
    "plt.axhline(y=average_inflation, color='orange', linestyle='--', label=f'Average Inflation: {average_inflation:.2f}%')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Inflation (%)')\n",
    "\n",
    "# Adding inflation values next to data points\n",
    "for year, infl in zip(years, inflation):\n",
    "    plt.text(year+.1, infl+0.3, f'{infl:.1f}%', ha='right', va='bottom')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.xticks(years)  # Set x-labels to match the years\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig(\"Iran_Inflation.png\", bbox_inches='tight', facecolor='white', dpi=100)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drowning AUC-ROC and AUPR Chart\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Set the custom font settings for scientific paper publications\n",
    "mpl.rcParams.update({\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times New Roman'],\n",
    "    'font.size': 18,\n",
    "    'font.weight': 'normal',\n",
    "    'axes.labelsize': 18,\n",
    "    'axes.titlesize': 18,\n",
    "    'axes.titleweight': 'bold',\n",
    "    'xtick.labelsize': 18,\n",
    "    'ytick.labelsize': 18,\n",
    "    'legend.fontsize': 18,\n",
    "})\n",
    "\n",
    "file_name = \"Main_Data\"\n",
    "random_state_numbers = [7, 42, 75, 101, 216]\n",
    "categorization_rules = \"R2B2\"\n",
    "preprocessing_methods = [\"MinMax\", \"Standard\"]\n",
    "target_columns = [\"r_dicho\", \"b_dicho\"]\n",
    "results_path = f'Results/No_drop/3_Algorithms_Results'\n",
    "\n",
    "\n",
    "wanted_columns = [\n",
    "    'Algorithm', 'Number_of_Features',\n",
    "    'auc_roc_mean', 'auprc_mean'\n",
    "]\n",
    "metric_cols = ['auc_roc_mean', 'auprc_mean']\n",
    "desired_columns_order = [\n",
    "    \"Scaling\", \"Alg\",\n",
    "    \"AUC-ROC\", \"AUPRC\"\n",
    "]\n",
    "al_names = [\"DT\", \"LR\", \"RF\", \"SVM\"]\n",
    "\n",
    "# Define the line styles for each line\n",
    "line_styles = ['-', '--', ':', '-.']\n",
    "marker_styles = ['o', 's', 'd', '^']\n",
    "n_features = 45\n",
    "\n",
    "for target_column in target_columns:\n",
    "    for preprocessing_method in preprocessing_methods:\n",
    "        df_list = []\n",
    "        for random_state in random_state_numbers:\n",
    "            tmp_path = f'{results_path}/{file_name}_new_{categorization_rules}/{target_column}/{random_state}_{preprocessing_method}'\n",
    "            tmp_resultFile = pd.read_csv(f'{tmp_path}/results_df.csv')\n",
    "            df_list.append(tmp_resultFile[wanted_columns])\n",
    "        \n",
    "        final_df = pd.concat(df_list)\n",
    "        tmp_mean_df = final_df.groupby(['Algorithm', 'Number_of_Features']).mean().reset_index()\n",
    "        # Set the index of the DataFrame as a MultiIndex based on 'Algorithm' and 'Number_of_Features'\n",
    "        tmp_mean_df.set_index(['Algorithm', 'Number_of_Features'], inplace=True)\n",
    "        \n",
    "        for metric in metric_cols:\n",
    "            fig = plt.figure(figsize=(16, 9))\n",
    "            gs = GridSpec(1, 1)\n",
    "\n",
    "            ax_scores = fig.add_subplot(gs[0, 0])\n",
    "            \n",
    "            # Plot each series with the corresponding line style\n",
    "            for i, col in enumerate(tmp_mean_df[metric].unstack(level=0).columns):\n",
    "                ax_scores.plot(\n",
    "                    tmp_mean_df[metric].unstack(level=0).index,\n",
    "                    tmp_mean_df[metric].unstack(level=0)[col],\n",
    "                    line_styles[i % len(line_styles)],  # Cycle through the line styles\n",
    "                    marker=marker_styles[i % len(marker_styles)],  # Cycle through the marker styles\n",
    "                    label=col\n",
    "                )\n",
    "                \n",
    "            # show grid lines\n",
    "            tick_positions = np.arange(0, n_features + 1, 10)\n",
    "            tick_positions = np.insert(tick_positions, 1, 1)\n",
    "            if tick_positions[-1] != n_features:\n",
    "                tick_positions = np.append(tick_positions, n_features)\n",
    "\n",
    "            ax_scores.set_xticks([i for i in range(1, n_features+1)])\n",
    "            ax_scores.set_xticklabels(['' if i not in tick_positions else str(i) for i in range(1, n_features+1)])\n",
    "\n",
    "            title = metric.replace(\"_\", \" \").title()\n",
    "            if \"Auprc\" in title:\n",
    "                title = title.replace(\"Auprc\",\"AUPR\")\n",
    "            if \"Auc Roc\" in title:\n",
    "                title = title.replace(\"Auc Roc\",\"AUC-ROC\")\n",
    "\n",
    "            # ax_scores.set_title(title)\n",
    "            ax_scores.set_xlabel('Number of Features')\n",
    "            ax_scores.set_ylabel('Score (%)')\n",
    "            ax_scores.grid(True)\n",
    "            \n",
    "            # show the legend\n",
    "            ax_scores.legend(loc='upper left')\n",
    "\n",
    "            # show/save the plot\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"conventional_{target_column}_{preprocessing_method}_{metric}.png\", bbox_inches='tight', facecolor='white', dpi=120)\n",
    "            # plt.show()\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generating Mean and Max Results Tables\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def round_2(number):\n",
    "    return np.round(number, 2)\n",
    "\n",
    "dataFiles_names = [\"Main_Data\"]\n",
    "random_state_numbers = [7, 42, 75, 101, 216]\n",
    "categorization_rules = \"R2B2\"\n",
    "preprocessing_methods = [\"MinMax\", \"Standard\"]\n",
    "target_columns = [\"r_dicho\", \"b_dicho\"]\n",
    "results_path = f'Results/No_drop/3_Algorithms_Results'\n",
    "\n",
    "desired_columns_order = [\n",
    "    \"Scaling\", \"Alg\",\n",
    "    \"Acc Cv\", \"Acc Te\",\n",
    "    \"Sp\", \"Se\", \"MCC\", \"F1\",\n",
    "    \"AUC-ROC\", \"AUPR\"\n",
    "]\n",
    "new_algorithms_names = [\"DT\", \"LR\", \"RF\", \"SVM\"]\n",
    "\n",
    "for file_name in dataFiles_names:\n",
    "    for target_column in target_columns:\n",
    "        mean_df_dict_all = {}\n",
    "        max_df_dict_all = {}\n",
    "        for preprocessing_method in preprocessing_methods:\n",
    "            df_dict = {}\n",
    "            for random_state in random_state_numbers:\n",
    "                tmp_path = f'{results_path}/{file_name}_new_{categorization_rules}/{target_column}/{random_state}_{preprocessing_method}'\n",
    "                tmp_resultFile = pd.read_csv(f'{tmp_path}/results_df.csv')\n",
    "                df_dict[f'{random_state}_{preprocessing_method}'] = tmp_resultFile\n",
    "\n",
    "            df_list = []\n",
    "            for key, df in df_dict.items():\n",
    "                df['preprocessing_method'] = key\n",
    "                df_list.append(df)\n",
    "\n",
    "            final_df = pd.concat(df_list)\n",
    "            tmp_mean_df = final_df.groupby(['Algorithm']).mean().reset_index()\n",
    "            tmp_mean_df.drop('Number_of_Features', inplace=True, axis=1)\n",
    "            tmp_std_df = final_df.groupby(['Algorithm']).std().reset_index()\n",
    "            tmp_std_df.drop('Number_of_Features', inplace=True, axis=1)\n",
    "\n",
    "\n",
    "            final_mean_df = pd.DataFrame({'Algorithm': tmp_mean_df['Algorithm'].values.tolist()})\n",
    "            for column in tmp_std_df.columns:\n",
    "                if \"_mean\" in column:\n",
    "                    column_value = []\n",
    "                    for i in range(len(tmp_mean_df)):\n",
    "                        new_value = f'{round_2(tmp_mean_df.loc[i, column])} \\u00B1 {round_2(tmp_std_df.loc[i, column])}'\n",
    "                        column_value.append(new_value)\n",
    "                    final_mean_df[column] = column_value\n",
    "\n",
    "            tmp_max_df = final_df.groupby(['Algorithm']).max().reset_index()\n",
    "            tmp_max_df.drop('Number_of_Features', inplace=True, axis=1)\n",
    "            final_max_df = pd.DataFrame({'Algorithm': tmp_max_df['Algorithm'].values.tolist()})\n",
    "            for column in tmp_max_df.columns:\n",
    "                if \"_mean\" in column:\n",
    "                    column_value = []\n",
    "                    for i in range(len(tmp_max_df)):\n",
    "                        Number_of_Features = final_df[\n",
    "                            (final_df[column] == tmp_max_df.loc[i, column])&(final_df['Algorithm']==tmp_max_df.loc[i, 'Algorithm'])\n",
    "                        ]['Number_of_Features'].tolist()[0]\n",
    "                        new_value = (round_2(tmp_max_df.loc[i, column]), Number_of_Features)                         \n",
    "                        column_value.append(new_value)\n",
    "                    final_max_df[column.replace(\"_mean\",\"_max\")] = column_value\n",
    "                    \n",
    "            mean_df_dict_all[preprocessing_method] = final_mean_df\n",
    "            max_df_dict_all[preprocessing_method] = final_max_df\n",
    "                \n",
    "        \n",
    "        dfs_with_key = []\n",
    "        for key, df in mean_df_dict_all.items():\n",
    "            df.insert(0, \"preprocessing_method\", key)  # Insert the key column at position 0\n",
    "            dfs_with_key.append(df)\n",
    "\n",
    "        mean_result_df = pd.concat(dfs_with_key, ignore_index=True)\n",
    "        \n",
    "        mean_result_df.columns = desired_columns_order\n",
    "        mean_result_df[\"Alg\"] = [\"DT\", \"LR\", \"RF\", \"SVM\"]*2\n",
    "        mean_result_df.to_csv(f'conventionalـ{target_column}_{file_name}_mean.csv', index=False)\n",
    "\n",
    "        dfs_with_key = []\n",
    "        for key, df in max_df_dict_all.items():\n",
    "            df.insert(0, \"preprocessing_method\", key)  # Insert the key column at position 0\n",
    "            dfs_with_key.append(df)\n",
    "\n",
    "        max_result_df = pd.concat(dfs_with_key, ignore_index=True)\n",
    "        max_result_df.columns = desired_columns_order\n",
    "        max_result_df[\"Alg\"] = new_algorithms_names*2\n",
    "        max_result_df.to_csv(f'conventionalـ{target_column}_{file_name}_max.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drowning AUC-ROC and AUPR Final Bar-Chart\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "\n",
    "# Set the custom font settings for scientific paper publications\n",
    "mpl.rcParams.update({\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times New Roman'],\n",
    "    'font.size': 18,\n",
    "    'font.weight': 'normal',\n",
    "    'axes.labelsize': 18,\n",
    "    'axes.titlesize': 18,\n",
    "    'axes.titleweight': 'bold',\n",
    "    'xtick.labelsize': 18,\n",
    "    'ytick.labelsize': 18,\n",
    "    'legend.fontsize': 18,\n",
    "})\n",
    "\n",
    "# Function to extract the metric values and standard deviations\n",
    "def extract_values_with_std(cell_value):\n",
    "    value, std = cell_value.split(' ± ')\n",
    "    return float(value), float(std)\n",
    "\n",
    "# Create the grouped 2x2 plot\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "target_columns = [\"r_cat\", \"b_cat\"]\n",
    "metric_cols = ['AUC-ROC', 'AUPR']\n",
    "xlabels = ['a', 'b', 'c', 'd'] \n",
    "\n",
    "tmp_data = pd.DataFrame()\n",
    "\n",
    "ax_index = 0\n",
    "for tr in target_columns:\n",
    "\n",
    "    file_name = f'{tr}_Main_Data_mean'\n",
    "\n",
    "    # Read the data from the CSV file\n",
    "    data = pd.read_csv(f'{file_name}.csv')\n",
    "\n",
    "       \n",
    "    for col in metric_cols:\n",
    "        data[col], data[col + ' std'] = zip(*data[col].map(extract_values_with_std))\n",
    "    \n",
    "    # Extract the necessary columns for plotting\n",
    "    alg_names = data['Alg'].unique()\n",
    "\n",
    "    \n",
    "    # Create grouped plots for each metric in the 4x2 grid\n",
    "    for j, metric in enumerate(metric_cols):   \n",
    "\n",
    "        row = ax_index // 2\n",
    "        col = ax_index % 2\n",
    "        ax = axs[row, col]\n",
    "\n",
    "        width = 0.4\n",
    "        x = np.arange(len(alg_names))\n",
    "        \n",
    "        ax.bar(x - width/2, data[data['Scaling'] == 'MinMax'][metric], width, label='MinMax', color='skyblue', edgecolor='black')\n",
    "        ax.bar(x + width/2, data[data['Scaling'] == 'Standard'][metric], width, label='Standard', color='orange', edgecolor='black')\n",
    "\n",
    "        # Add error bars for standard deviation\n",
    "        ax.errorbar(x - width/2, data[data['Scaling'] == 'MinMax'][metric],\n",
    "                    yerr=data[data['Scaling'] == 'MinMax'][metric + ' std'],\n",
    "                    fmt='none', ecolor='black', capsize=3, elinewidth=1, marker='_', markersize=6)\n",
    "        ax.errorbar(x + width/2, data[data['Scaling'] == 'Standard'][metric],\n",
    "                    yerr=data[data['Scaling'] == 'Standard'][metric + ' std'],\n",
    "                    fmt='none', ecolor='black', capsize=3, elinewidth=1, marker='_', markersize=6)\n",
    "        \n",
    "        \n",
    "        ax.set_xlabel(f'({xlabels[ax_index]})')\n",
    "        ax.set_ylabel('Score (%)')\n",
    "        ax.set_title(metric_cols[j])\n",
    "        \n",
    "        # Set the ylim based on stds\n",
    "        min_val = min(min(data[data['Scaling'] == 'MinMax'][metric] - 2 * data[data['Scaling'] == 'MinMax'][metric + ' std']),\n",
    "                    min(data[data['Scaling'] == 'Standard'][metric] - 2 * data[data['Scaling'] == 'Standard'][metric + ' std']))\n",
    "        max_val = max(max(data[data['Scaling'] == 'MinMax'][metric] + 2 * data[data['Scaling'] == 'MinMax'][metric + ' std']),\n",
    "                    max(data[data['Scaling'] == 'Standard'][metric] + 2 * data[data['Scaling'] == 'Standard'][metric + ' std']))\n",
    "        ax.set_ylim(min_val, max_val)\n",
    "\n",
    "        # Show algorithm names below the bars\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(alg_names, ha='center')\n",
    "\n",
    "        # Set the legend for the grouped bars\n",
    "        ax.legend(loc='upper left')\n",
    "\n",
    "        ax_index += 1\n",
    "\n",
    "# Adjust the layout and spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure as an image file for publication\n",
    "plt.savefig(f'conventional_bar_plot.png', bbox_inches='tight', facecolor='white', dpi=120)\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generating Feature Ranking Mean\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "results_path = \"Results/No_drop/2_Prepared_Data/Main_Data_new_R2B2\"\n",
    "random_state_numbers = [7, 42, 75, 101, 216]\n",
    "preprocessing_methods = [\"MinMax\", \"Standard\"]\n",
    "target_columns = ['r_dicho', 'b_dicho']\n",
    "nFolds = 5\n",
    "\n",
    "\n",
    "def get_finalScores(features_lists, features):\n",
    "    final_scores = pd.DataFrame(data = {'Features':features})\n",
    "    for i in range(len(features_lists)):\n",
    "        tmp_scores = []\n",
    "        for feature in final_scores[\"Features\"]:\n",
    "            tmp_scores.append(features_lists[i].index(feature)+1)\n",
    "        final_scores[i+1] = tmp_scores\n",
    "\n",
    "    modes = []\n",
    "    means = []\n",
    "    stds = []\n",
    "    for i in range(len(final_scores)):\n",
    "        data = final_scores.iloc[i, 1:]\n",
    "        modes.append(data.mode()[0])\n",
    "        means.append(data.mean())\n",
    "        stds.append(data.std())\n",
    "    final_scores['Mode'] = modes\n",
    "    final_scores['Mean'] = means\n",
    "    final_scores['Std'] = stds\n",
    "    \n",
    "    final_scores = final_scores.sort_values(by=['Mode', 'Mean', \"Std\"])\n",
    "    final_scores.reset_index(drop=True, inplace=True)\n",
    "    return final_scores\n",
    "\n",
    "def get_aggregatedScores(features_lists, features):\n",
    "    final_scores = pd.DataFrame(data = {'Features':features})\n",
    "    for key, value in features_lists.items():\n",
    "        tmp_scores = []\n",
    "        for feature in final_scores[\"Features\"]:\n",
    "            tmp_scores.append(value.index(feature)+1)\n",
    "        final_scores[key] = tmp_scores\n",
    "\n",
    "    final_scores = final_scores.sort_values(by=list(features_lists.keys())[0])\n",
    "    final_scores.reset_index(drop=True, inplace=True)\n",
    "    return final_scores\n",
    "\n",
    "agg_list = {}\n",
    "for tr in target_columns:\n",
    "    for pp in preprocessing_methods:\n",
    "        features_list = []\n",
    "        for rs in random_state_numbers:\n",
    "            tmp_path = f'{results_path}/{tr}/{rs}_{pp}/ranked_features'\n",
    "\n",
    "            for i in range(1, nFolds+1):\n",
    "                tmp_rankedFeatures = pd.read_csv(f'{tmp_path}/KBest_fold_{i}.csv')\n",
    "                features_list.append(tmp_rankedFeatures[\"Features\"].tolist())\n",
    "\n",
    "        final_df = get_finalScores(features_list, features_list[0])        \n",
    "        final_df.to_csv(f\"{tr}_KBest_rankedFeatures_{pp}.csv\", index=False)\n",
    "        \n",
    "        agg_list[f'{tr}_{pp}'] = final_df['Features'].tolist()\n",
    "\n",
    "agg_dfs = get_aggregatedScores(agg_list, list(agg_list.values())[0])\n",
    "tmp_features = agg_dfs[\"Features\"].tolist()\n",
    "agg_dfs.to_csv(f\"conventional_final_KBest_rankedFeatures.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
